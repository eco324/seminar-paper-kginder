---
title: "Data Appendix to \"MAKE A TITLE\""
author: "Kate Ginder"
output: 
  pdf_document:
    toc: true
    number_sections: true
---
```{r setup, echo = F, message = F}
knitr::opts_chunk$set(results = 'asis', cache = F)
library(tidyverse)
library(summarytools)
st_options(plain.ascii = F,
           style = "rmarkdown",
           footnote = NA,
           subtitle.emphasis = F,
           dfSummary.silent = T,
           dfSummary.valid.col = F,
           tmp.img.dir = "./tmp",
           dfSummary.style = "grid")

#The following custom function simplifies the process of writing dfSummaries to html files
export_summary_table <- function(dfSummary_output){
  data_info <- attr(dfSummary_output, "data_info")
  ds_name <- data_info$Data.frame
  print(dfSummary_output,
      file = str_c("output/", ds_name, "_summary.html"),
      method = "browser",
      report.title = ds_name)
}
```

```{r set dfSummary css style, echo = F, include = F}
st_css()
```


# Appendix description
*Your Data Appendix should begin with a brief statement explaining its purpose like the following one.*

This Data Appendix documents the data used in "MAKE A TITLE". It was prepared in a Rmarkdown document that contains both the documentation and the R code used to prepare the data used in the final estimation. It also includes descriptive statistics for both the original data and the final dataset, with a discussion of any issues of note.

The datasets used directly by the final analysis are saved in `processed-data/` at the end of this file.

*Note: this document structure will require you to re-run steps of your analysis multiple times. If your code takes a long time, please come talk with me about strategies to reduce run time or save earlier results.*



# Raw data
*Each dataset you use will have its own documentation section. The next subsection in this document (Dataset description) is a template. You can copy this section and paste it into your document each time you need to add a section for a new dataset. Note that each line in the Dataset description section __must__ end with two spaces.* 

This section documents the data sets used in this analysis.

## Dataset description
**Citation:** Put citation here in APA or other consistent format that you will use throughout the project. Include a hyperlink if applicable.  
**Date Downloaded:** 04/17/2020  
**Filename:** Compost Tracker 3.0.xlsx. 
**Unit of observation:** amount of compost recorded in dinning halls daily  
**Dates covered:**  February 2020 - April 2020  

### To obtain a copy

To obtain a copy of this data set please contact Susan Sayre at ssayre@smith.edu

### Importable version

**Filename:** importable-data/Raw Data Seminar Paper/Compost Tracker 4.0.csv

The following changes were made to create the importable files.

1.The file was originally opened in excel on a Mac
2.The header reading "Composting Feb & April" was deleted.  It was causing the variable names to import incorrectly.
3. The document was then saved as a csv file

### Variable descriptions

The following data is from two of the Smith College dinning serviouses

- **dates:** Date of the month.  
- **day of the week:** Day of the week the meal is served on.
- **# of plates - king:** Number of plates per night used in King dinning hall. 
- **lb composting - king:** Pounds of compost per night King dinning hall.
- **# of plates - cutter:** Number of plates per night used in Cutter dinning hall. 
- **lb composting - cutter:** Pounds of compost per night Cutter dinning hall.
- **Meal number:** Rotating menu cycle. 

### Data import code and summary

*Once you've described the variables, enter an R chunk by selecting Code -> Insert Chunk, or Ctrl+Alt+I, give it a name to describe the dataset you are importing. After importing, export a dataframe summary using the command.*


```{r reading in variable names}
library(readr)
Compost_Tracker_4_0 <- read_csv("Raw Data Seminar Paper/Compost Tracker 4.0.csv")
View(Compost_Tracker_4_0)


Compost_Tracker_4.0.csv <- lapply(Compost_Tracker_4.0, read_csv) %>% bind_rows() %>% 
  select(kingplates = #_of_plates_-_King,
           kingcompost = lb_composting_-_King,
         cutterplates = #_of_plates_-_cutter,
           cuttercompost = lb_compost_-_Cutter)


'export_summary_table(dfSummary(Compost_Tracker_4_0))
```

The data was coding correctly for the variables with number to be codded as numerical variables.  The only categorical variable in the data was Day of the week.

# Analysis Variables

This section should include a description of all the variables that are used in your final analysis. At the end of the section, you should save all of these variables in the processed_data folder of your repository.

Variables used in the final analysis are

- **dates:** Date of the month.  
- **day of the week:** Day of the week the meal is served on.
- **kingplates:** Number of plates per night used in King dinning hall. 
- **kingcompost:** Pounds of compost per night King dinning hall.
- **cutterplates:** Number of plates per night used in Cutter dinning hall. 
- **cuttercompost:** Pounds of compost per night Cutter dinning hall.
- **Meal number:** Rotating menu cycle.


```{r summary stats}
summary(Compost_Tracker_4_0)

```


```{r}
ggplot(data = Compost_Tracker_4_0, aes(x = #_plates_-_king, y = lb_compost_-_King)) + geom_point() + geom_smooth(method = "lm")
```







# Discussion of Data

*This section should include a discussion of any data patterns you notice based on the summaries created in the code above.*

The data 


































